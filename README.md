# ğŸ“ OSF Paper Extraction and Result Comparison

This project helps in automating the process of downloading research paper PDFs using paper titles and IDs. It supports searching via **Semantic Scholar API**, and saves the PDFs locally along with their status in CSV files, and now 
## Research Paper Analysis

This tool also includes functionality to extract and summarize specific sections of research papers and compares research paper PDFs with R script execution logs using either OpenAI or Gemini AI models.


---

## ğŸ“ Project Structure
```bash
osf_paper_extraction/
â”‚
â”œâ”€â”€ notebooks/                    # Jupyter notebooks for preprocessing datasets
â”œâ”€â”€ semantic-papers/              # Research papers downloaded from Semantic-Scholar
â”œâ”€â”€ papers1/                      # Research papers downloaded from Core-API and other resources
â”œâ”€â”€ csv_files/                    # CSVs contaiing metadata and project IDs with status.
â”œâ”€â”€ test/                         # Folder for storing test PDFs
â”‚
â”œâ”€â”€ download_semantic_papers.py   # Downloads PDFs via Semantic Scholar API
â”œâ”€â”€ download1.py                  # Downloads PDFs via CORE API
â”œâ”€â”€ run_openai.py                 # Main pipeline for OpenAI-based summarization and Rscript result comparison
â”œâ”€â”€ run_gemini.py                 # Pipeline for gemini-based pdf and Rscript result comparison
â”œâ”€â”€ runai_ml.py                   # Pipelines for summarization using other free API resources.
â”œâ”€â”€ markdown_docling.py           # (Optional) Pdf to markdown conversion.
â”œâ”€â”€ results                       # Stores extracted sections in markdown format
â”œâ”€â”€ report.ipynb                  # Notebook for documentation of findings in the process.
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # Project documentation
```

## ğŸ”§ Setup Instructions

1. **Clone the repository**  
   ```bash
   git clone https://github.com/Mehtab07/osf_paper_extraction.git
   cd osf_paper_extraction
   Create a `.env` file in the root directory with your API keys:
   pip install -r requirements.txt

## To Run
  ```bash
  OpenAI Version (`run_openai.py`)
  # Processes PDF by converting to markdown first, then compares with log file. By default, it loads a test PDF (test/7h94n.pdf) and its Rscript result from 7h94n_execution.log, it can be edited to any section or full paper
  ```
  ```bash
  Gemini Version (`run_gemini.py`)
  # It takes PDF directly, then compares with log file. By default, it loads a test PDF (test/7h94n.pdf) and its Rscript result from 7h94n_execution.log.
  ```
## Notes  
Rate Limiting: Both APIs while downloading Research Papers may enforce rate limits. The scripts implement exponential backoff and randomized sleep to reduce the chance of hitting limits.

PDF Availability: Not all titles will have a downloadable PDF. These cases are marked in the status column of the output CSV.

Folder Creation: The scripts automatically create the output folders (papers/, papers1/) if they do not exist.

Section Extraction: The section split logic currently uses common academic headers like Introduction, Method, Conclusion, etc. This can be extended as needed.